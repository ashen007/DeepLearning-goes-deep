{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, AveragePooling2D, Lambda, Input, Dense, Flatten\n",
    "from tensorflow.keras.layers import concatenate, BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU, PReLU, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = SGD(learning_rate=1e-2, momentum=9e-1)\n",
    "weight_decay = 5e-4\n",
    "\n",
    "\n",
    "# vgg with leaky relu\n",
    "def vgg_net16_lr(input_shape=(224, 224, 3), classes=None, alpha=0.3):\n",
    "    # input layer\n",
    "    input_layer = Input(shape=input_shape, name='input_')\n",
    "\n",
    "    # first conv block\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(\n",
    "        input_layer)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n",
    "\n",
    "    # second conv block\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n",
    "\n",
    "    # third conv block\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n",
    "\n",
    "    # fourth conv block\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n",
    "\n",
    "    # fifth conv block\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n",
    "\n",
    "    # classifier\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=512)(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=512)(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(input_layer, x)\n",
    "    model.compile(optimizer=optimizer, loss=categorical_crossentropy, metrics=['accuracy'])\n",
    "    # model.summary()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# inception with leaky relu\n",
    "def inception(x, filters, projection, classes=None, aux=False, name=None, aux_name=None, alpha=0.3):\n",
    "    f_1x1, f_3x3, f_3x3_reduce, f_5x5, f_5x5_reduce = filters\n",
    "    x1 = Conv2D(filters=f_1x1, kernel_size=(1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x1 = LeakyReLU(alpha=alpha)(x1)\n",
    "    x3_reducer = Conv2D(filters=f_3x3_reduce, kernel_size=(1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x3_reducer = LeakyReLU(alpha=alpha)(x3_reducer)\n",
    "    x5_reducer = Conv2D(filters=f_5x5_reduce, kernel_size=(1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x5_reducer = LeakyReLU(alpha=alpha)(x5_reducer)\n",
    "    pool = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "\n",
    "    x3 = Conv2D(filters=f_3x3, kernel_size=(3, 3), strides=(1, 1), padding='same')(x3_reducer)\n",
    "    x3 = LeakyReLU(alpha=alpha)(x3)\n",
    "    x5 = Conv2D(filters=f_5x5, kernel_size=(5, 5), strides=(1, 1), padding='same')(x5_reducer)\n",
    "    x5 = LeakyReLU(alpha=alpha)(x5)\n",
    "    proj = Conv2D(filters=projection, kernel_size=(1, 1), strides=(1, 1), padding='same')(pool)\n",
    "    proj = LeakyReLU(alpha=alpha)(proj)\n",
    "\n",
    "    x = concatenate([x1, x3, x5, proj], axis=3, name=name)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def model_builder(shape, classes, alpha=0.3):\n",
    "    input_layer = Input(shape=shape)\n",
    "    x = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same')(input_layer)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = Conv2D(filters=192, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=alpha)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception(x, [64, 128, 96, 32, 16], projection=32, alpha=alpha, name='inception_3a')\n",
    "    x = inception(x, [128, 192, 128, 96, 32], projection=64, alpha=alpha, name='inception_3b')\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception(x, [192, 208, 96, 48, 16], projection=64, alpha=alpha, name='inception_4a')\n",
    "\n",
    "    aux_1 = AveragePooling2D(pool_size=(5, 5), strides=(3, 3), padding='valid')(x)\n",
    "    aux_1 = Conv2D(filters=128, kernel_size=(1, 1), strides=(1, 1), padding='valid')(aux_1)\n",
    "    aux_1 = LeakyReLU(alpha=alpha)\n",
    "    aux_1 = Dense(units=1024)(aux_1)\n",
    "    aux_1 = LeakyReLU(alpha=alpha)\n",
    "    aux_1 = Dropout(rate=0.7)(aux_1)\n",
    "    aux_1 = Flatten()(aux_1)\n",
    "    aux_out1 = Dense(units=classes, activation='softmax', name='aux_out1')(aux_1)\n",
    "\n",
    "    x = inception(x, [160, 224, 112, 64, 24], projection=64, alpha=alpha, name='inception_4b')\n",
    "    x = inception(x, [128, 256, 128, 64, 24], projection=64, alpha=alpha, name='inception_4c')\n",
    "    x = inception(x, [112, 288, 144, 64, 32], projection=64, alpha=alpha, name='inception_4d')\n",
    "    x = inception(x, [256, 320, 160, 128, 32], projection=128, alpha=alpha, name='inception_4e')\n",
    "\n",
    "    aux_2 = AveragePooling2D(pool_size=(5, 5), strides=(3, 3), padding='valid')(x)\n",
    "    aux_2 = Conv2D(filters=128, kernel_size=(1, 1), strides=(1, 1), padding='valid')(aux_2)\n",
    "    aux_2 = LeakyReLU(alpha=alpha)\n",
    "    aux_2 = Dense(units=1024)(aux_2)\n",
    "    aux_2 = LeakyReLU(alpha=alpha)\n",
    "    aux_2 = Dropout(rate=0.7)(aux_2)\n",
    "    aux_2 = Flatten()(aux_2)\n",
    "    aux_out2 = Dense(units=classes, activation='softmax', name='aux_out2')(aux_2)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception(x, [256, 320, 160, 128, 32], projection=128, alpha=alpha, name='inception_5a')\n",
    "    x = inception(x, [384, 384, 192, 128, 48], projection=128, alpha=alpha, name='inception_5b')\n",
    "    x = AveragePooling2D(pool_size=(7, 7), strides=(1, 1))(x)\n",
    "    x = Dropout(rate=0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    output_layer = Dense(units=classes, activation='softmax', name='main_out')(x)\n",
    "\n",
    "    model = Model(input_layer, [output_layer, aux_out1, aux_out2])\n",
    "    model.compile(optimizer=Adam(), loss=categorical_crossentropy,\n",
    "                  loss_weights={'main_out': 1, 'aux_out1': 0.3, 'aux_out2': 0.3},\n",
    "                  metrics=['accuracy'])\n",
    "    # model.summary()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vgg_a1 = vgg_net16_lr(input_shape=(96, 96, 3), classes=121, alpha=0.01)\n",
    "vgg_a2 = vgg_net16_lr(input_shape=(96, 96, 3), classes=121, alpha=0.3)\n",
    "vgg_a3 = vgg_net16_lr(input_shape=(96, 96, 3), classes=121, alpha=1.0)\n",
    "vgg_a4 = vgg_net16_lr(input_shape=(96, 96, 3), classes=121, alpha=3.3)\n",
    "vgg_a5 = vgg_net16_lr(input_shape=(96, 96, 3), classes=121, alpha=10.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inception_a1 = model_builder(shape=(96, 96, 3), classes=121, alpha=0.01)\n",
    "inception_a2 = model_builder(shape=(96, 96, 3), classes=121, alpha=0.3)\n",
    "inception_a3 = model_builder(shape=(96, 96, 3), classes=121, alpha=1.0)\n",
    "inception_a4 = model_builder(shape=(96, 96, 3), classes=121, alpha=3.3)\n",
    "inception_a5 = model_builder(shape=(96, 96, 3), classes=121, alpha=10.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.1,\n",
    "                              patience=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator(rescale=1 / 255.,\n",
    "                               vertical_flip=True,\n",
    "                               horizontal_flip=True,\n",
    "                               rotation_range=20,\n",
    "                               zoom_range=0.3,\n",
    "                               validation_split=0.2)\n",
    "\n",
    "train_batch = generator.flow_from_directory(directory='../input/ndsb-training-data/train/',\n",
    "                                            target_size=(96, 96),\n",
    "                                            subset='training')\n",
    "\n",
    "valid_batch = generator.flow_from_directory(directory='../input/ndsb-training-data/train/',\n",
    "                                            target_size=(96, 96),\n",
    "                                            subset='validation')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***VGGNet training***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_a1 = vgg_a1.fit(train_batch,\n",
    "                        epochs=50,\n",
    "                        validation_data=valid_batch,\n",
    "                        steps_per_epoch=256,\n",
    "                        callbacks=[reduce_lr])\n",
    "\n",
    "pd.DataFrame(history_a1.history).to_pickle('history_a1.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_a2 = vgg_a2.fit(train_batch,\n",
    "                        epochs=50,\n",
    "                        validation_data=valid_batch,\n",
    "                        steps_per_epoch=256,\n",
    "                        callbacks=[reduce_lr])\n",
    "\n",
    "pd.DataFrame(history_a2.history).to_pickle('history_a2.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_a3 = vgg_a3.fit(train_batch,\n",
    "                        epochs=50,\n",
    "                        validation_data=valid_batch,\n",
    "                        steps_per_epoch=256,\n",
    "                        callbacks=[reduce_lr])\n",
    "\n",
    "pd.DataFrame(history_a3.history).to_pickle('history_a3.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_a4 = vgg_a4.fit(train_batch,\n",
    "                        epochs=50,\n",
    "                        validation_data=valid_batch,\n",
    "                        steps_per_epoch=256,\n",
    "                        callbacks=[reduce_lr])\n",
    "\n",
    "pd.DataFrame(history_a4.history).to_pickle('history_a4.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_a5 = vgg_a5.fit(train_batch,\n",
    "                        epochs=50,\n",
    "                        validation_data=valid_batch,\n",
    "                        steps_per_epoch=256,\n",
    "                        callbacks=[reduce_lr])\n",
    "\n",
    "pd.DataFrame(history_a5.history).to_pickle('history_a5.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ***Inception***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_a1_in = inception_a1.fit(train_batch,\n",
    "                                 epochs=50,\n",
    "                                 validation_data=valid_batch,\n",
    "                                 steps_per_epoch=256,\n",
    "                                 callbacks=[reduce_lr])\n",
    "\n",
    "pd.DataFrame(history_a1_in.history).to_pickle('history_a1_in.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_a2_in = inception_a2.fit(train_batch,\n",
    "                                 epochs=50,\n",
    "                                 validation_data=valid_batch,\n",
    "                                 steps_per_epoch=256,\n",
    "                                 callbacks=[reduce_lr])\n",
    "\n",
    "pd.DataFrame(history_a2_in.history).to_pickle('history_a2_in.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_a3_in = inception_a3.fit(train_batch,\n",
    "                                 epochs=50,\n",
    "                                 validation_data=valid_batch,\n",
    "                                 steps_per_epoch=256,\n",
    "                                 callbacks=[reduce_lr])\n",
    "\n",
    "pd.DataFrame(history_a3_in.history).to_pickle('history_a3_in.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_a4_in = inception_a4.fit(train_batch,\n",
    "                                 epochs=50,\n",
    "                                 validation_data=valid_batch,\n",
    "                                 steps_per_epoch=256,\n",
    "                                 callbacks=[reduce_lr])\n",
    "\n",
    "pd.DataFrame(history_a4_in.history).to_pickle('history_a4_in.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history_a5_in = inception_a5.fit(train_batch,\n",
    "                                 epochs=50,\n",
    "                                 validation_data=valid_batch,\n",
    "                                 steps_per_epoch=256,\n",
    "                                 callbacks=[reduce_lr])\n",
    "\n",
    "pd.DataFrame(history_a5_in.history).to_pickle('history_a5_in.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}