{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-03-31T08:42:05.201347Z",
     "iopub.execute_input": "2022-03-31T08:42:05.201927Z",
     "iopub.status.idle": "2022-03-31T08:42:05.704093Z",
     "shell.execute_reply.started": "2022-03-31T08:42:05.201895Z",
     "shell.execute_reply": "2022-03-31T08:42:05.703358Z"
    },
    "trusted": true
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T02:32:29.057839Z",
     "iopub.execute_input": "2022-03-31T02:32:29.058057Z",
     "iopub.status.idle": "2022-03-31T02:32:29.070760Z",
     "shell.execute_reply.started": "2022-03-31T02:32:29.058023Z",
     "shell.execute_reply": "2022-03-31T02:32:29.070096Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_image(path, mode='RGB'):\n",
    "    return PIL.Image.open(path)\n",
    "\n",
    "\n",
    "def to_array(image):\n",
    "    return np.asarray(image)\n",
    "\n",
    "\n",
    "def to_image(array, mode='RGB'):\n",
    "    return PIL.Image.fromarray(np.uint8(array), mode=mode)\n",
    "\n",
    "\n",
    "def resize(image, size):\n",
    "    return tf.image.resize(image, size)\n",
    "\n",
    "\n",
    "def resize_smallest_side_different_scales(image, smallest_side_to=(224, 384)):\n",
    "    height, width = to_array(image).shape[:2]\n",
    "    scaled_list = []\n",
    "\n",
    "    if height < width:\n",
    "\n",
    "        for scale in smallest_side_to:\n",
    "            scaled = tf.image.resize(image, (scale, width))\n",
    "            scaled_list.append(scaled)\n",
    "\n",
    "        return scaled_list\n",
    "\n",
    "    else:\n",
    "\n",
    "        for scale in smallest_side_to:\n",
    "            scaled = tf.image.resize(image, (height, scale))\n",
    "            scaled_list.append(scaled)\n",
    "\n",
    "        return scaled_list\n",
    "\n",
    "\n",
    "def resize_with_aspect_ratio(image, target_width=(128, 256, 512), input_shape=(224, 224)):\n",
    "    h, w = to_array(image).shape[:2]\n",
    "    r = h / w\n",
    "    resized = []\n",
    "\n",
    "    for width in target_width:\n",
    "        resized_h = int(r * width)\n",
    "        resized_img = resize(image, (resized_h, width))\n",
    "        resized.append(\n",
    "            to_image(resize(tf.image.resize_with_crop_or_pad(resized_img, input_shape[0], input_shape[1]), (128, 128))))\n",
    "\n",
    "    return resized\n",
    "\n",
    "\n",
    "def bounding_boxes(offsets, dim):\n",
    "    boxes = []\n",
    "\n",
    "    for i in offsets:\n",
    "        offset_height, offset_width = i\n",
    "        target_height, target_width = dim\n",
    "        boxes.append([offset_height, offset_width, target_height, target_width])\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def random_sectioning(image, offsets, dims):\n",
    "    boxes = bounding_boxes(offsets, dims)\n",
    "    image_sections = []\n",
    "    height, width = to_array(image).shape[:2]\n",
    "\n",
    "    if (height < height // 2 + dims[0]) and (width < width // 2 + dims[1]):\n",
    "        image = tf.image.resize(image, (dims[0] * 2, dims[1] * 2))\n",
    "\n",
    "    if (height > height // 2 + dims[0]) and (width < width // 2 + dims[1]):\n",
    "        image = tf.image.resize(image, (height, dims[1] * 2))\n",
    "\n",
    "    if (height < height // 2 + dims[0]) and (width > width // 2 + dims[1]):\n",
    "        image = tf.image.resize(image, (dims[0] * 2, width))\n",
    "\n",
    "    for box in boxes:\n",
    "        if random.choice([True, False]):\n",
    "            section = tf.image.crop_to_bounding_box(image, box[0], box[1], box[2], box[3])\n",
    "            image_sections.append(resize(section, (128, 128)))\n",
    "\n",
    "    return image_sections\n",
    "\n",
    "\n",
    "def aggressive_cropping(image, copies, crop_window, resize_smallest_side=None, output_shape=(128, 128)):\n",
    "    global resized_copies\n",
    "\n",
    "    if resize_smallest_side is not None:\n",
    "        if isinstance(resize_smallest_side, int):\n",
    "            img = resize(to_array(image), (resize_smallest_side, resize_smallest_side))\n",
    "\n",
    "        if isinstance(resize_smallest_side, (list, tuple)):\n",
    "            resized_copies = [tf.image.resize(to_array(image), (size, size)) for size in resize_smallest_side]\n",
    "\n",
    "    if isinstance(crop_window, int):\n",
    "        crops = [tf.image.random_crop(to_array(image), (crop_window, crop_window)) for _ in range(copies)]\n",
    "\n",
    "        return [resize(crop_img, output_shape) for crop_img in crops]\n",
    "\n",
    "    elif isinstance(crop_window, (list, tuple)):\n",
    "        crops = [tf.image.random_crop(to_array(image), crop_window) for _ in range(copies)]\n",
    "\n",
    "        return [resize(crop_img, output_shape) for crop_img in crops]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T02:32:36.399097Z",
     "iopub.execute_input": "2022-03-31T02:32:36.399536Z",
     "iopub.status.idle": "2022-03-31T02:32:36.422501Z",
     "shell.execute_reply.started": "2022-03-31T02:32:36.399500Z",
     "shell.execute_reply": "2022-03-31T02:32:36.421563Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def pipeline(file_name, src, dst, label):\n",
    "    processed = []\n",
    "    image = load_image(os.path.join(src, file_name))\n",
    "    height, width = to_array(image).shape[:2]\n",
    "\n",
    "    sections = random_sectioning(to_array(image),\n",
    "                                 [[0, 0], [height // 2, 0], [0, width // 2], [height // 2, width // 2],\n",
    "                                  [height // 4, width // 4]],\n",
    "                                 [224, 224])\n",
    "    resize_small_side = resize_smallest_side_different_scales(to_array(image), (224, 384))\n",
    "    resized_with_aspect_ratio = resize_with_aspect_ratio(to_array(image))\n",
    "    resized_original = tf.image.resize_with_pad(to_array(image), 224, 224)\n",
    "\n",
    "    for i, arr in enumerate(sections):\n",
    "        filename = f'r-sec-{i}-{file_name}'\n",
    "        processed.append([filename, label])\n",
    "        to_image(arr).save(os.path.join(dst, filename))\n",
    "\n",
    "    for i, arr in enumerate(resized_with_aspect_ratio):\n",
    "        filename = f'r-to-ar-{i}-{file_name}'\n",
    "        processed.append([filename, label])\n",
    "        to_image(arr).save(os.path.join(dst, filename))\n",
    "\n",
    "    for j, img in enumerate(resize_small_side):\n",
    "        rand_crop = aggressive_cropping(to_image(img), 2, (224, 224, 3))\n",
    "\n",
    "        for i, arr in enumerate(rand_crop):\n",
    "            filename = f'agr-crop-{j}-{i}-{file_name}'\n",
    "            processed.append([filename, label])\n",
    "            to_image(arr).save(os.path.join(dst, filename))\n",
    "\n",
    "    to_image(resized_original).save(os.path.join(dst, file_name))\n",
    "\n",
    "    return processed"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T02:32:41.323052Z",
     "iopub.execute_input": "2022-03-31T02:32:41.323301Z",
     "iopub.status.idle": "2022-03-31T02:32:41.334215Z",
     "shell.execute_reply.started": "2022-03-31T02:32:41.323271Z",
     "shell.execute_reply": "2022-03-31T02:32:41.333325Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_meta = pd.read_csv('../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv')\n",
    "train_meta"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T02:32:46.295870Z",
     "iopub.execute_input": "2022-03-31T02:32:46.296130Z",
     "iopub.status.idle": "2022-03-31T02:32:46.347855Z",
     "shell.execute_reply.started": "2022-03-31T02:32:46.296103Z",
     "shell.execute_reply": "2022-03-31T02:32:46.347192Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "src = '../input/sorghum-id-fgvc-9/train_images/'\n",
    "dst = 'train'\n",
    "meta = []\n",
    "\n",
    "if not os.path.isdir(dst):\n",
    "    os.mkdir(dst)\n",
    "\n",
    "for i in range(train_meta.shape[0]):\n",
    "    file, label = train_meta.iloc[i]\n",
    "\n",
    "    if os.path.exists(os.path.join(src, file)):\n",
    "        temp = pipeline(file, src, dst, label)\n",
    "        meta.append(temp)\n",
    "\n",
    "    print(f'{i + 1}/{train_meta.shape[0]}', end='\\r')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T02:32:49.235859Z",
     "iopub.execute_input": "2022-03-31T02:32:49.236187Z",
     "iopub.status.idle": "2022-03-31T03:53:26.429248Z",
     "shell.execute_reply.started": "2022-03-31T02:32:49.236156Z",
     "shell.execute_reply": "2022-03-31T03:53:26.428512Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "meta[0]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:53:26.430889Z",
     "iopub.execute_input": "2022-03-31T03:53:26.431588Z",
     "iopub.status.idle": "2022-03-31T03:53:26.438360Z",
     "shell.execute_reply.started": "2022-03-31T03:53:26.431547Z",
     "shell.execute_reply": "2022-03-31T03:53:26.437499Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# df1 = pd.DataFrame(empty, columns=['a_files', 'label'])\n",
    "# df2 = pd.DataFrame(os.listdir('train'), columns=['a_files'])\n",
    "# final = df2.merge(df1, how='inner', on='a_files')\n",
    "# final"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T02:02:06.644899Z",
     "iopub.status.idle": "2022-03-31T02:02:06.645468Z",
     "shell.execute_reply.started": "2022-03-31T02:02:06.645237Z",
     "shell.execute_reply": "2022-03-31T02:02:06.645262Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "empty = []\n",
    "\n",
    "for i in range(len(meta)):\n",
    "    empty += meta[i][:11]\n",
    "\n",
    "len(empty)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:53:47.156370Z",
     "iopub.execute_input": "2022-03-31T03:53:47.157150Z",
     "iopub.status.idle": "2022-03-31T03:53:47.173954Z",
     "shell.execute_reply.started": "2022-03-31T03:53:47.157110Z",
     "shell.execute_reply": "2022-03-31T03:53:47.173203Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "final = pd.DataFrame(empty, columns=['a_files', 'label'])\n",
    "final"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:54:10.394993Z",
     "iopub.execute_input": "2022-03-31T03:54:10.395246Z",
     "iopub.status.idle": "2022-03-31T03:54:10.444576Z",
     "shell.execute_reply.started": "2022-03-31T03:54:10.395217Z",
     "shell.execute_reply": "2022-03-31T03:54:10.443916Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "figure, axes = plt.subplots(nrows=1, ncols=6, figsize=[18, 6], dpi=300)\n",
    "\n",
    "for i in range(len(axes)):\n",
    "    axes[i].imshow(load_image(os.path.join('train', random.choice(final['a_files'].values))))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:55:24.004172Z",
     "iopub.execute_input": "2022-03-31T03:55:24.004613Z",
     "iopub.status.idle": "2022-03-31T03:55:25.296850Z",
     "shell.execute_reply.started": "2022-03-31T03:55:24.004572Z",
     "shell.execute_reply": "2022-03-31T03:55:25.293618Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def inception(x, filters, projection, classes=None, aux=False, name=None, aux_name=None):\n",
    "    f_1x1, f_3x3, f_3x3_reduce, f_5x5, f_5x5_reduce = filters\n",
    "    x1 = Conv2D(filters=f_1x1, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n",
    "    x3_reducer = Conv2D(filters=f_3x3_reduce, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n",
    "    x5_reducer = Conv2D(filters=f_5x5_reduce, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n",
    "    pool = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "\n",
    "    x3 = Conv2D(filters=f_3x3, kernel_size=(3, 3), strides=(1, 1), activation=relu, padding='same')(x3_reducer)\n",
    "    x5 = Conv2D(filters=f_5x5, kernel_size=(5, 5), strides=(1, 1), activation=relu, padding='same')(x5_reducer)\n",
    "    proj = Conv2D(filters=projection, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(pool)\n",
    "\n",
    "    x = concatenate([x1, x3, x5, proj], axis=3, name=name)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def model_builder(shape, classes):\n",
    "    input_layer = Input(shape=shape)\n",
    "    x = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), activation=relu, padding='same')(input_layer)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n",
    "    x = Conv2D(filters=192, kernel_size=(3, 3), strides=(1, 1), activation=relu, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception(x, [64, 128, 96, 32, 16], projection=32, name='inception_3a')\n",
    "    x = inception(x, [128, 192, 128, 96, 32], projection=64, name='inception_3b')\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception(x, [192, 208, 96, 48, 16], projection=64, name='inception_4a')\n",
    "\n",
    "    aux_1 = AveragePooling2D(pool_size=(5, 5), strides=(3, 3), padding='valid')(x)\n",
    "    aux_1 = Conv2D(filters=128, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='valid')(aux_1)\n",
    "    aux_1 = Dense(units=1024, activation=relu)(aux_1)\n",
    "    aux_1 = Dropout(rate=0.7)(aux_1)\n",
    "    aux_1 = Flatten()(aux_1)\n",
    "    aux_out1 = Dense(units=classes, activation=softmax, name='aux_out1')(aux_1)\n",
    "\n",
    "    x = inception(x, [160, 224, 112, 64, 24], projection=64, name='inception_4b')\n",
    "    x = inception(x, [128, 256, 128, 64, 24], projection=64, name='inception_4c')\n",
    "    x = inception(x, [112, 288, 144, 64, 32], projection=64, name='inception_4d')\n",
    "    x = inception(x, [256, 320, 160, 128, 32], projection=128, name='inception_4e')\n",
    "\n",
    "    aux_2 = AveragePooling2D(pool_size=(5, 5), strides=(3, 3), padding='valid')(x)\n",
    "    aux_2 = Conv2D(filters=128, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='valid')(aux_2)\n",
    "    aux_2 = Dense(units=1024, activation=relu)(aux_2)\n",
    "    aux_2 = Dropout(rate=0.7)(aux_2)\n",
    "    aux_2 = Flatten()(aux_2)\n",
    "    aux_out2 = Dense(units=classes, activation=softmax, name='aux_out2')(aux_2)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception(x, [256, 320, 160, 128, 32], projection=128, name='inception_5a')\n",
    "    x = inception(x, [384, 384, 192, 128, 48], projection=128, name='inception_5b')\n",
    "    x = AveragePooling2D(pool_size=(7, 7), strides=(1, 1))(x)\n",
    "    x = Dropout(rate=0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    output_layer = Dense(units=classes, activation=softmax, name='main_out')(x)\n",
    "\n",
    "    model = Model(input_layer, [output_layer, aux_out1, aux_out2])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=categorical_crossentropy,\n",
    "                  loss_weights={'main_out': 1, 'aux_out1': 0.3, 'aux_out2': 0.3},\n",
    "                  metrics=['accuracy', tfa.metrics.F1Score(num_classes=classes, threshold=0.5)])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:53:26.439837Z",
     "iopub.execute_input": "2022-03-31T03:53:26.440193Z",
     "iopub.status.idle": "2022-03-31T03:53:26.467143Z",
     "shell.execute_reply.started": "2022-03-31T03:53:26.440157Z",
     "shell.execute_reply": "2022-03-31T03:53:26.466474Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = model_builder((224, 224, 3), 100)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:53:26.469226Z",
     "iopub.execute_input": "2022-03-31T03:53:26.469624Z",
     "iopub.status.idle": "2022-03-31T03:53:27.100907Z",
     "shell.execute_reply.started": "2022-03-31T03:53:26.469590Z",
     "shell.execute_reply": "2022-03-31T03:53:27.100273Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generator = ImageDataGenerator(rescale=1 / 255.,\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True,\n",
    "                               brightness_range=(0.3, 0.6),\n",
    "                               validation_split=0.3)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:53:27.102082Z",
     "iopub.execute_input": "2022-03-31T03:53:27.102318Z",
     "iopub.status.idle": "2022-03-31T03:53:27.108242Z",
     "shell.execute_reply.started": "2022-03-31T03:53:27.102282Z",
     "shell.execute_reply": "2022-03-31T03:53:27.107503Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_batches = generator.flow_from_dataframe(dataframe=final,\n",
    "                                              directory='train',\n",
    "                                              x_col='a_files',\n",
    "                                              y_col='label',\n",
    "                                              batch_size=32,\n",
    "                                              target_size=(224, 224),\n",
    "                                              subset='training')\n",
    "\n",
    "validation_batches = generator.flow_from_dataframe(dataframe=final,\n",
    "                                                   directory='train',\n",
    "                                                   x_col='a_files',\n",
    "                                                   y_col='label',\n",
    "                                                   batch_size=32,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   subset='validation')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:55:40.386880Z",
     "iopub.execute_input": "2022-03-31T03:55:40.387144Z",
     "iopub.status.idle": "2022-03-31T03:55:44.497685Z",
     "shell.execute_reply.started": "2022-03-31T03:55:40.387115Z",
     "shell.execute_reply": "2022-03-31T03:55:44.496913Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "next(train_batches)[0].shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:55:47.058873Z",
     "iopub.execute_input": "2022-03-31T03:55:47.059255Z",
     "iopub.status.idle": "2022-03-31T03:55:47.186039Z",
     "shell.execute_reply.started": "2022-03-31T03:55:47.059207Z",
     "shell.execute_reply": "2022-03-31T03:55:47.185031Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=10,\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.1,\n",
    "                              patience=5)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:55:56.485398Z",
     "iopub.execute_input": "2022-03-31T03:55:56.485894Z",
     "iopub.status.idle": "2022-03-31T03:55:56.492363Z",
     "shell.execute_reply.started": "2022-03-31T03:55:56.485856Z",
     "shell.execute_reply": "2022-03-31T03:55:56.491607Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(x=train_batches,\n",
    "                    validation_data=validation_batches,\n",
    "                    epochs=100,\n",
    "                    steps_per_epoch=2048,\n",
    "                    validation_steps=1024,\n",
    "                    callbacks=[early_stop, reduce_lr])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T03:56:46.430851Z",
     "iopub.execute_input": "2022-03-31T03:56:46.431111Z",
     "iopub.status.idle": "2022-03-31T08:22:06.140096Z",
     "shell.execute_reply.started": "2022-03-31T03:56:46.431083Z",
     "shell.execute_reply": "2022-03-31T08:22:06.138367Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "temp = pd.DataFrame(history.history)\n",
    "temp.to_pickle('history.pkl')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T08:28:03.727999Z",
     "iopub.execute_input": "2022-03-31T08:28:03.728273Z",
     "iopub.status.idle": "2022-03-31T08:28:03.745387Z",
     "shell.execute_reply.started": "2022-03-31T08:28:03.728243Z",
     "shell.execute_reply": "2022-03-31T08:28:03.744674Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.save('model.hdf5')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T08:28:08.405752Z",
     "iopub.execute_input": "2022-03-31T08:28:08.406015Z",
     "iopub.status.idle": "2022-03-31T08:28:08.958905Z",
     "shell.execute_reply.started": "2022-03-31T08:28:08.405985Z",
     "shell.execute_reply": "2022-03-31T08:28:08.958045Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_batches.class_indices"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T08:46:41.350433Z",
     "iopub.execute_input": "2022-03-31T08:46:41.351018Z",
     "iopub.status.idle": "2022-03-31T08:46:41.361036Z",
     "shell.execute_reply.started": "2022-03-31T08:46:41.350983Z",
     "shell.execute_reply": "2022-03-31T08:46:41.360105Z"
    },
    "trusted": true
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_preds = []\n",
    "\n",
    "for i, file in enumerate(os.listdir('../input/sorghum-id-fgvc-9/test')):\n",
    "    img = resize(to_array(load_image(os.path.join('../input/sorghum-id-fgvc-9/test', file))) / 255., (224, 224))\n",
    "    img_arr = np.expand_dims(to_array(img), axis=0)\n",
    "    preds = (\n",
    "    np.argmax(model.predict(img_arr)[0]), np.argmax(model.predict(img_arr)[1]), np.argmax(model.predict(img_arr)[2]))\n",
    "    top = ss.mode(preds)[0][0]\n",
    "\n",
    "    label = list(train_batches.class_indices.keys())[list(train_batches.class_indices.values()).index(top)]\n",
    "\n",
    "    test_preds.append([file, label])\n",
    "\n",
    "    print(f'{i + 1}/{len(os.listdir(\"../input/sorghum-id-fgvc-9/test\"))}', end='\\r')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T08:53:37.199428Z",
     "iopub.execute_input": "2022-03-31T08:53:37.199715Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_preds = pd.DataFrame(test_preds, columns=['filename', 'cultivar'])\n",
    "test_preds.to_csv('submission_1.csv', index=False)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}