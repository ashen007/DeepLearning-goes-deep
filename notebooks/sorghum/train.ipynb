{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport random\nimport PIL.Image\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom matplotlib import pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-30T12:42:24.861123Z","iopub.execute_input":"2022-03-30T12:42:24.861782Z","iopub.status.idle":"2022-03-30T12:42:30.533545Z","shell.execute_reply.started":"2022-03-30T12:42:24.861689Z","shell.execute_reply":"2022-03-30T12:42:30.532704Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def load_image(path, mode='RGB'):\n    return PIL.Image.open(path)\n\n\ndef to_array(image):\n    return np.asarray(image)\n\n\ndef to_image(array, mode='RGB'):\n    return PIL.Image.fromarray(np.uint8(array), mode=mode)\n\ndef resize(image, size):\n    return tf.image.resize(image, size)\n\n\ndef resize_smallest_side_different_scales(image, smallest_side_to=(128, 256, 384)):\n    height, width = to_array(image).shape[:2]\n    scaled_list = []\n\n    if height < width:\n\n        for scale in smallest_side_to:\n            scaled = tf.image.resize(image, (scale, width))\n            scaled_list.append(scaled)\n\n        return scaled_list\n\n    else:\n\n        for scale in smallest_side_to:\n            scaled = tf.image.resize(image, (height, scale))\n            scaled_list.append(scaled)\n\n        return scaled_list\n\n\ndef resize_with_aspect_ratio(image, target_width=(128, 256, 512), input_shape=(224, 224)):\n    h, w = to_array(image).shape[:2]\n    r = h / w\n    resized = []\n\n    for width in target_width:\n        resized_h = int(r * width)\n        resized_img = resize(image, (resized_h, width))\n        resized.append(to_image(tf.image.resize_with_crop_or_pad(resized_img, input_shape[0], input_shape[1])))\n\n    return resized\n\n\ndef bounding_boxes(offsets, dim):\n    boxes = []\n\n    for i in offsets:\n        offset_height, offset_width = i\n        target_height, target_width = dim\n        boxes.append([offset_height, offset_width, target_height, target_width])\n\n    return boxes\n\n\ndef random_sectioning(image, offsets, dims):\n    boxes = bounding_boxes(offsets, dims)\n    image_sections = []\n    height, width = to_array(image).shape[:2]\n    \n    if (height < height//2 + dims[0]) and (width < width//2 + dims[1]):\n        image = tf.image.resize(image, (dims[0]*2, dims[1]*2))\n    \n    if (height > height//2 + dims[0]) and (width < width//2 + dims[1]):\n        image = tf.image.resize(image, (height, dims[1]*2))\n    \n    if (height < height//2 + dims[0]) and (width > width//2 + dims[1]):\n        image = tf.image.resize(image, (dims[0]*2, width))\n\n    for box in boxes:\n        if random.choice([True, False]):\n            section = tf.image.crop_to_bounding_box(image, box[0], box[1], box[2], box[3])\n            image_sections.append(section)\n\n    return image_sections\n\n\ndef aggressive_cropping(image, copies, crop_window, resize_smallest_side=None, output_shape=(224, 224)):\n    global resized_copies\n\n    if resize_smallest_side is not None:\n        if isinstance(resize_smallest_side, int):\n            img = resize(to_array(image), (resize_smallest_side, resize_smallest_side))\n\n        if isinstance(resize_smallest_side, (list, tuple)):\n            resized_copies = [tf.image.resize(to_array(image), (size, size)) for size in resize_smallest_side]\n\n    if isinstance(crop_window, int):\n        crops = [tf.image.random_crop(to_array(image), (crop_window, crop_window)) for _ in range(copies)]\n\n        return [resize(crop_img, output_shape) for crop_img in crops]\n\n    elif isinstance(crop_window, (list, tuple)):\n        crops = [tf.image.random_crop(to_array(image), crop_window) for _ in range(copies)]\n\n        return [resize(crop_img, output_shape) for crop_img in crops]","metadata":{"execution":{"iopub.status.busy":"2022-03-30T12:42:30.535192Z","iopub.execute_input":"2022-03-30T12:42:30.535432Z","iopub.status.idle":"2022-03-30T12:42:30.559149Z","shell.execute_reply.started":"2022-03-30T12:42:30.535393Z","shell.execute_reply":"2022-03-30T12:42:30.558369Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Pipeline","metadata":{}},{"cell_type":"code","source":"def pipeline(file_name, src, dst, label):\n    processed = []\n    image = load_image(os.path.join(src, file_name))\n    height, width = to_array(image).shape[:2]\n\n    sections = random_sectioning(to_array(image),\n                                 [[0, 0], [height // 2, 0], [0, width // 2], [height // 2, width // 2],\n                                  [height // 4, width // 4]],\n                                 [224, 224])\n    resize_small_side = resize_smallest_side_different_scales(to_array(image), (224, 256, 384))\n    resized_with_aspect_ratio = resize_with_aspect_ratio(to_array(image))\n    resized_original = tf.image.resize_with_pad(to_array(image), 224, 224)\n\n    for i, arr in enumerate(sections):\n        filename = f'r-sec-{i}-{file_name}'\n        processed.append([filename, label])\n        to_image(arr).save(os.path.join(dst, filename))\n\n    for i, arr in enumerate(resized_with_aspect_ratio):\n        filename = f'r-to-ar-{i}-{file_name}'\n        processed.append([filename, label])\n        to_image(arr).save(os.path.join(dst, filename))\n\n    for img in resize_small_side:\n        rand_crop = aggressive_cropping(to_image(img), 4, (224, 224, 3))\n\n        for i, arr in enumerate(rand_crop):\n            filename = f'agr-crop-{i}-{file_name}'\n            processed.append([filename, label])\n            to_image(arr).save(os.path.join(dst, filename))\n            \n    to_image(resized_original).save(os.path.join(dst,file_name))\n    \n    return processed","metadata":{"execution":{"iopub.status.busy":"2022-03-30T12:42:30.560571Z","iopub.execute_input":"2022-03-30T12:42:30.561071Z","iopub.status.idle":"2022-03-30T12:42:30.574674Z","shell.execute_reply.started":"2022-03-30T12:42:30.561005Z","shell.execute_reply":"2022-03-30T12:42:30.573940Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_meta = pd.read_csv('../input/sorghum-id-fgvc-9/train_cultivar_mapping.csv')\ntrain_meta","metadata":{"execution":{"iopub.status.busy":"2022-03-30T12:42:30.577876Z","iopub.execute_input":"2022-03-30T12:42:30.578109Z","iopub.status.idle":"2022-03-30T12:42:30.633224Z","shell.execute_reply.started":"2022-03-30T12:42:30.578080Z","shell.execute_reply":"2022-03-30T12:42:30.632442Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"src = '../input/sorghum-id-fgvc-9/train_images/'\ndst = 'train'\nmeta = []\n\nif not os.path.isdir(dst):\n    os.mkdir(dst)\n\nfor i in range(train_meta.shape[0]):\n    file, label = train_meta.iloc[i]\n    \n    if os.path.exists(os.path.join(src, file)):\n        temp = pipeline(file, src, dst, label)\n        meta.append(temp)\n    \n    print(f'{i + 1}/{train_meta.shape[0]}', end='\\r')","metadata":{"execution":{"iopub.status.busy":"2022-03-30T12:43:18.273949Z","iopub.execute_input":"2022-03-30T12:43:18.274219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}