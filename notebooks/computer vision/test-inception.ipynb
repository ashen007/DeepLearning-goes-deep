{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import os\nimport pandas as pd\nimport tensorflow_addons as tfa\nimport numpy as np\nimport PIL.Image\nimport tensorflow as tf\n\n# from tensorflow.keras.utils import load_img\nfrom tensorflow.keras.models import Model\n\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\n\nfrom tensorflow.keras.activations import relu, softmax\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.utils import array_to_img, img_to_array",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-03-13T04:29:21.692557Z",
     "iopub.execute_input": "2022-03-13T04:29:21.6929Z",
     "iopub.status.idle": "2022-03-13T04:29:27.091311Z",
     "shell.execute_reply.started": "2022-03-13T04:29:21.692802Z",
     "shell.execute_reply": "2022-03-13T04:29:27.090516Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "traing_metadata = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')\n\ndef cropping(image, filename=None, path=None, dst=None, central=True, random=False, fraction_low=0.5, fraction_high=0.9,\n             random_width=224, random_height=224, copies=3, save_original=True):\n    \"\"\"\n    :type copies: int\n    :type random_height: int\n    :type random_width: int\n    :type fraction_high: float\n    :type fraction_low: float\n    :type random: bool\n    :type central: bool\n    :type save_original: bool\n    :type dst: basestring\n    :type path: basestring\n    \"\"\"\n    if path is not None:\n        images = os.listdir(path)\n\n        for image in images:\n            image_path = os.path.join(path, image)\n            img = img_to_array(PIL.Image.open(image_path))\n\n            if central:\n                for i in range(copies):\n                    crop_area = np.round(np.random.uniform(fraction_low, fraction_high), 2)\n                    cc_img = tf.image.central_crop(img, central_fraction=crop_area)\n\n                    if dst is not None:\n                        array_to_img(cc_img).save(os.path.join(dst, f'cc_img_{i}_{image}'))\n\n                    else:\n                        return array_to_img(cc_img)\n\n            elif random:\n                for i in range(copies):\n                    rc_img = tf.image.random_crop(img, size=[random_width, random_height, 3])\n\n                    if dst is not None:\n                        array_to_img(rc_img).save(os.path.join(dst, f'rc_img_{i}_{image}'))\n\n                    else:\n                        return array_to_img(rc_img)\n\n            if save_original:\n                array_to_img(img).save(os.path.join(dst, image))\n\n    if image:\n        if central:\n            for i in range(copies):\n                crop_area = np.round(np.random.uniform(fraction_low, fraction_high), 2)\n                cc_img = tf.image.central_crop(img_to_array(image), central_fraction=crop_area)\n\n                if dst is not None:\n                    array_to_img(cc_img).save(os.path.join(dst, f'cc_img_{i}_{filename}'))\n\n                else:\n                    return array_to_img(cc_img)\n\n        elif random:\n            for i in range(copies):\n                rc_img = tf.image.random_crop(img_to_array(image),\n                                              size=[random_width, random_height, 3])\n\n                if dst is not None:\n                    array_to_img(rc_img).save(os.path.join(dst, f'rc_img_{i}_{filename}'))\n\n                else:\n                    return array_to_img(rc_img)\n\n                \ndef random_changes_to_color_properties(path, dst, delta=None, gamma_transformation=True, change_contrast=True,\n                                       factor=None, copies=1, save_original=False):\n    \"\"\"\n    :type copies: int\n    :type factor: int\n    :type change_contrast: bool\n    :type gamma_transformation: bool\n    :type delta: float\n    :type save_original: bool\n    :type dst: basestring\n    :type path: basestring\n    \"\"\"\n    images = os.listdir(path)\n    i = 0\n\n    for image in images:\n        image_path = os.path.join(path, image)\n        img = img_to_array(PIL.Image.open(image_path))\n\n        if delta is None:\n            for i in range(copies):\n                change_factor = np.round(np.random.uniform(-1, 1), 2)\n                bc_img = array_to_img(tf.image.adjust_brightness(img, change_factor))\n                hue_img = array_to_img(tf.image.adjust_hue(img, change_factor))\n                sat_img = array_to_img(tf.image.adjust_saturation(img, change_factor))\n\n                # save transformed images\n                bc_img.save(os.path.join(dst, f'bc_{i}_{image}'))\n                hue_img.save(os.path.join(dst, f'hue_{i}_{image}'))\n                sat_img.save(os.path.join(dst, f'sat_{i}_{image}'))\n\n        elif isinstance(delta, float):\n            for i in range(copies):\n                change_factor = np.round(np.random.uniform(-1 * delta, 1 * delta), 2)\n                bc_img = array_to_img(tf.image.adjust_brightness(img, change_factor))\n                hue_img = array_to_img(tf.image.adjust_hue(img, change_factor))\n                sat_img = array_to_img(tf.image.adjust_saturation(img, change_factor))\n\n                # save transformed images\n                bc_img.save(os.path.join(dst, f'bc_{i}_{image}'))\n                hue_img.save(os.path.join(dst, f'hue_{i}_{image}'))\n                sat_img.save(os.path.join(dst, f'sat_{i}_{image}'))\n\n        if factor is None:\n            if gamma_transformation:\n                for i in range(copies):\n                    gamma = np.round(np.random.uniform(1, 5), 2)\n                    gamma_img = array_to_img(tf.image.adjust_gamma(img, gamma))\n                    gamma_img.save(os.path.join(dst, f'gamma_img_{i}_{image}'))\n\n            if change_contrast:\n                for i in range(copies):\n                    change_factor = np.round(np.random.uniform(-5, 5), 2)\n                    cont_img = array_to_img(tf.image.adjust_contrast(img, change_factor))\n                    cont_img.save(os.path.join(dst, f'cont_img_{i}_{image}'))\n\n        elif isinstance(factor, int):\n            if gamma_transformation:\n                for i in range(copies):\n                    gamma = np.round(np.random.uniform(1, factor), 2)\n                    gamma_img = array_to_img(tf.image.adjust_gamma(img, gamma))\n                    gamma_img.save(os.path.join(dst, f'gamma_img_{i}_{image}'))\n\n            if change_contrast:\n                for i in range(copies):\n                    factor = np.round(np.random.uniform(-1 * factor, factor), 2)\n                    cont_img = array_to_img(tf.image.adjust_contrast(img, factor))\n                    cont_img.save(os.path.join(dst, f'cont_img_{i}_{image}'))\n\n        if save_original:\n            array_to_img(img).save(os.path.join(dst, image))\n          \n        i += 1\n        print(f\"steps: {i + 1}/{len(images)} \", end='\\r')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-13T04:29:27.092933Z",
     "iopub.execute_input": "2022-03-13T04:29:27.093169Z",
     "iopub.status.idle": "2022-03-13T04:29:27.156265Z",
     "shell.execute_reply.started": "2022-03-13T04:29:27.093136Z",
     "shell.execute_reply": "2022-03-13T04:29:27.155608Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "for i in range(traing_metadata.shape[0]):\n    file_name, label = traing_metadata.iloc[i]\n    \n    if not os.path.isdir('train'):\n        os.mkdir('train')\n        \n    if not os.path.isdir(os.path.join('train',label)):\n        os.mkdir(os.path.join('train', label))\n        \n    src = os.path.join('../input/plant-pathology-2021-fgvc8/train_images/', file_name)\n    dst = os.path.join('train',label)\n    img = PIL.Image.open(src)\n    \n    cc_img = cropping(img, central=True, random=False, fraction_low=0.75, fraction_high=0.9, copies=1, save_original=False)\n    cropping(cc_img, file_name, dst=dst, central=False, random=True, random_width=224, random_height=224, copies=5, save_original=False)\n    \n    print(f\"steps: {i + 1}/{traing_metadata.shape[0]} \", end='\\r')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-13T04:29:27.159155Z",
     "iopub.execute_input": "2022-03-13T04:29:27.159345Z",
     "iopub.status.idle": "2022-03-13T10:05:42.560795Z",
     "shell.execute_reply.started": "2022-03-13T04:29:27.159321Z",
     "shell.execute_reply": "2022-03-13T10:05:42.560209Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "for sub_dir in os.listdir('train'):\n    src = os.path.join('train', sub_dir)\n    dst = os.path.join('train', sub_dir)\n    \n    random_changes_to_color_properties(src, dst)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-13T10:05:42.562964Z",
     "iopub.execute_input": "2022-03-13T10:05:42.563274Z",
     "iopub.status.idle": "2022-03-13T10:31:35.405189Z",
     "shell.execute_reply.started": "2022-03-13T10:05:42.56324Z",
     "shell.execute_reply": "2022-03-13T10:31:35.404469Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "len(os.listdir('train'))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-13T10:31:35.406478Z",
     "iopub.execute_input": "2022-03-13T10:31:35.407886Z",
     "iopub.status.idle": "2022-03-13T10:31:35.416343Z",
     "shell.execute_reply.started": "2022-03-13T10:31:35.407841Z",
     "shell.execute_reply": "2022-03-13T10:31:35.415688Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def inception(x, filters, projection, name=None):\n    f_1x1, f_3x3, f_3x3_reduce, f_5x5, f_5x5_reduce = filters\n    x1 = Conv2D(filters=f_1x1, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n    x3_reducer = Conv2D(filters=f_3x3_reduce, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n    x5_reducer = Conv2D(filters=f_5x5_reduce, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n    pool = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n\n    x3 = Conv2D(filters=f_3x3, kernel_size=(3, 3), strides=(1, 1), activation=relu, padding='same')(x3_reducer)\n    x5 = Conv2D(filters=f_5x5, kernel_size=(5, 5), strides=(1, 1), activation=relu, padding='same')(x5_reducer)\n    proj = Conv2D(filters=projection, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(pool)\n\n    x = concatenate([x1, x3, x5, proj], axis=3, name=name)\n\n    return x\n\n\ndef model_builder(shape, classes):\n    input_layer = Input(shape=shape)\n    x = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), activation=relu, padding='same')(input_layer)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n    x = Conv2D(filters=192, kernel_size=(3, 3), strides=(1, 1), activation=relu, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n    x = inception(x, [64, 128, 96, 32, 16], projection=32, name='inception_3a')\n    x = inception(x, [128, 192, 128, 96, 32], projection=64, name='inception_3b')\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n    x = inception(x, [192, 208, 96, 48, 16], projection=64, name='inception_4a')\n    x = inception(x, [160, 224, 112, 64, 24], projection=64, name='inception_4b')\n    x = inception(x, [128, 256, 128, 64, 24], projection=64, name='inception_4c')\n    x = inception(x, [112, 288, 144, 64, 32], projection=64, name='inception_4d')\n    x = inception(x, [256, 320, 160, 128, 32], projection=128, name='inception_4e')\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n    x = inception(x, [256, 320, 160, 128, 32], projection=128, name='inception_5a')\n    x = inception(x, [384, 384, 192, 128, 48], projection=128, name='inception_5b')\n    x = AveragePooling2D(pool_size=(7, 7), strides=(1, 1))(x)\n    x = Dropout(rate=0.4)(x)\n    x = Flatten()(x)\n    output_layer = Dense(units=classes, activation=softmax)(x)\n\n    model = Model(input_layer, output_layer)\n    model.compile(optimizer=Adam(), loss=categorical_crossentropy,\n                  metrics=['accuracy', tfa.metrics.F1Score(num_classes=classes, threshold=0.5)])\n    model.summary()\n\n    return model",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-13T10:31:35.417446Z",
     "iopub.execute_input": "2022-03-13T10:31:35.417898Z",
     "iopub.status.idle": "2022-03-13T10:31:35.440698Z",
     "shell.execute_reply.started": "2022-03-13T10:31:35.417859Z",
     "shell.execute_reply": "2022-03-13T10:31:35.439866Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_generator = ImageDataGenerator(rescale=1 / 255.,\n                                     validation_split=0.3)\n\ntrain_set = train_generator.flow_from_directory('train',\n                                                target_size=(224, 224),\n                                                batch_size=96,\n                                                subset='training')\nval_set = train_generator.flow_from_directory('train',\n                                              target_size=(224, 224),\n                                              batch_size=96,\n                                              subset='validation')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-13T10:31:35.442926Z",
     "iopub.execute_input": "2022-03-13T10:31:35.443402Z",
     "iopub.status.idle": "2022-03-13T10:32:03.821884Z",
     "shell.execute_reply.started": "2022-03-13T10:31:35.4433Z",
     "shell.execute_reply": "2022-03-13T10:32:03.821006Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model = model_builder((224, 224, 3), 12)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-13T10:32:03.825657Z",
     "iopub.execute_input": "2022-03-13T10:32:03.826118Z",
     "iopub.status.idle": "2022-03-13T10:32:04.439457Z",
     "shell.execute_reply.started": "2022-03-13T10:32:03.826086Z",
     "shell.execute_reply": "2022-03-13T10:32:04.438706Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "early_stop = EarlyStopping(monitor='val_loss',\n                           patience=10,\n                           restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.1,\n                              patience=10)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-13T10:32:04.440786Z",
     "iopub.execute_input": "2022-03-13T10:32:04.441045Z",
     "iopub.status.idle": "2022-03-13T10:32:04.446755Z",
     "shell.execute_reply.started": "2022-03-13T10:32:04.440994Z",
     "shell.execute_reply": "2022-03-13T10:32:04.446086Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "history = model.fit(x=train_set,\n          validation_data=val_set,\n          epochs=100,\n          callbacks=[early_stop, reduce_lr])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-13T10:32:04.449359Z",
     "iopub.execute_input": "2022-03-13T10:32:04.449592Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "temp = pd.DataFrame(history.history)\ntemp.to_pickle('inception_random_crop_history.pkl')",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model.save('inception_random_crop.hdf5')",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}