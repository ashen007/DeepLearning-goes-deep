{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import os\nimport random\nimport pandas as pd\nimport tensorflow_addons as tfa\nimport numpy as np\nimport PIL.Image\nimport tensorflow as tf\n\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.models import Model\n\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\n\nfrom tensorflow.keras.activations import relu, softmax\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.utils import array_to_img, img_to_array",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-15T04:30:25.103842Z",
     "iopub.execute_input": "2022-03-15T04:30:25.10418Z",
     "iopub.status.idle": "2022-03-15T04:30:30.346337Z",
     "shell.execute_reply.started": "2022-03-15T04:30:25.104153Z",
     "shell.execute_reply": "2022-03-15T04:30:30.345599Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "traing_metadata = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')\n\ndef cropping(image, filename=None, path=None, dst=None, central=True, random=False, fraction_low=0.5, fraction_high=0.9,\n             random_width=224, random_height=224, copies=3, save_original=True):\n    \"\"\"\n    :type copies: int\n    :type random_height: int\n    :type random_width: int\n    :type fraction_high: float\n    :type fraction_low: float\n    :type random: bool\n    :type central: bool\n    :type save_original: bool\n    :type dst: basestring\n    :type path: basestring\n    \"\"\"\n    if path is not None:\n        images = os.listdir(path)\n\n        for image in images:\n            image_path = os.path.join(path, image)\n            img = img_to_array(PIL.Image.open(image_path))\n\n            if central:\n                for i in range(copies):\n                    crop_area = np.round(np.random.uniform(fraction_low, fraction_high), 2)\n                    cc_img = tf.image.central_crop(img, central_fraction=crop_area)\n\n                    if dst is not None:\n                        array_to_img(cc_img).save(os.path.join(dst, f'cc_img_{i}_{image}'))\n\n                    else:\n                        return array_to_img(cc_img)\n\n            elif random:\n                for i in range(copies):\n                    rc_img = tf.image.random_crop(img, size=[random_width, random_height, 3])\n\n                    if dst is not None:\n                        array_to_img(rc_img).save(os.path.join(dst, f'rc_img_{i}_{image}'))\n\n                    else:\n                        return array_to_img(rc_img)\n\n            if save_original:\n                array_to_img(img).save(os.path.join(dst, image))\n\n    if image:\n        if central:\n            for i in range(copies):\n                crop_area = np.round(np.random.uniform(fraction_low, fraction_high), 2)\n                cc_img = tf.image.central_crop(img_to_array(image), central_fraction=crop_area)\n\n                if dst is not None:\n                    array_to_img(cc_img).save(os.path.join(dst, f'cc_img_{i}_{filename}'))\n\n                else:\n                    return array_to_img(cc_img)\n\n        elif random:\n            for i in range(copies):\n                rc_img = tf.image.random_crop(img_to_array(image),\n                                              size=[random_width, random_height, 3])\n\n                if dst is not None:\n                    array_to_img(rc_img).save(os.path.join(dst, f'rc_img_{i}_{filename}'))\n\n                else:\n                    return array_to_img(rc_img)\n\n                \ndef random_changes_to_color_properties(path, dst, delta=None, gamma_transformation=True, change_contrast=True,\n                                       factor=None, copies=1, save_original=False):\n    \"\"\"\n    :type copies: int\n    :type factor: int\n    :type change_contrast: bool\n    :type gamma_transformation: bool\n    :type delta: float\n    :type save_original: bool\n    :type dst: basestring\n    :type path: basestring\n    \"\"\"\n    images = os.listdir(path)\n    i = 0\n\n    for image in images:\n        image_path = os.path.join(path, image)\n        img = img_to_array(PIL.Image.open(image_path))\n\n        if delta is None:\n            for i in range(copies):\n                change_factor = np.round(np.random.uniform(-1, 1), 2)\n                bc_img = array_to_img(tf.image.adjust_brightness(img, change_factor))\n                hue_img = array_to_img(tf.image.adjust_hue(img, change_factor))\n                sat_img = array_to_img(tf.image.adjust_saturation(img, change_factor))\n\n                # save transformed images\n                bc_img.save(os.path.join(dst, f'bc_{i}_{image}'))\n                hue_img.save(os.path.join(dst, f'hue_{i}_{image}'))\n                sat_img.save(os.path.join(dst, f'sat_{i}_{image}'))\n\n        elif isinstance(delta, float):\n            for i in range(copies):\n                change_factor = np.round(np.random.uniform(-1 * delta, 1 * delta), 2)\n                bc_img = array_to_img(tf.image.adjust_brightness(img, change_factor))\n                hue_img = array_to_img(tf.image.adjust_hue(img, change_factor))\n                sat_img = array_to_img(tf.image.adjust_saturation(img, change_factor))\n\n                # save transformed images\n                bc_img.save(os.path.join(dst, f'bc_{i}_{image}'))\n                hue_img.save(os.path.join(dst, f'hue_{i}_{image}'))\n                sat_img.save(os.path.join(dst, f'sat_{i}_{image}'))\n\n        if factor is None:\n            if gamma_transformation:\n                for i in range(copies):\n                    gamma = np.round(np.random.uniform(1, 5), 2)\n                    gamma_img = array_to_img(tf.image.adjust_gamma(img, gamma))\n                    gamma_img.save(os.path.join(dst, f'gamma_img_{i}_{image}'))\n\n            if change_contrast:\n                for i in range(copies):\n                    change_factor = np.round(np.random.uniform(-2, 2), 2)\n                    cont_img = array_to_img(tf.image.adjust_contrast(img, change_factor))\n                    cont_img.save(os.path.join(dst, f'cont_img_{i}_{image}'))\n\n        elif isinstance(factor, int):\n            if gamma_transformation:\n                for i in range(copies):\n                    gamma = np.round(np.random.uniform(1, factor), 2)\n                    gamma_img = array_to_img(tf.image.adjust_gamma(img, gamma))\n                    gamma_img.save(os.path.join(dst, f'gamma_img_{i}_{image}'))\n\n            if change_contrast:\n                for i in range(copies):\n                    factor = np.round(np.random.uniform(-1 * factor, factor), 2)\n                    cont_img = array_to_img(tf.image.adjust_contrast(img, factor))\n                    cont_img.save(os.path.join(dst, f'cont_img_{i}_{image}'))\n\n        if save_original:\n            array_to_img(img).save(os.path.join(dst, image))\n          \n        i += 1\n        print(f\"steps: {i}/{len(images)} \", end='\\r')",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-15T04:30:30.347863Z",
     "iopub.execute_input": "2022-03-15T04:30:30.348146Z",
     "iopub.status.idle": "2022-03-15T04:30:30.420194Z",
     "shell.execute_reply.started": "2022-03-15T04:30:30.34811Z",
     "shell.execute_reply": "2022-03-15T04:30:30.419548Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "sample = traing_metadata.sample(n=10)\nfigure, axes = plt.subplots(nrows=2, ncols=5, figsize=[16,4], dpi=300)\naxes = axes.ravel()\n\nfor i in range(sample.shape[0]):\n    file_name, label = sample.iloc[i]\n    src = os.path.join('../input/resizing-high-quality-images/train/', file_name)\n    img = PIL.Image.open(src)\n    \n    axes[i].imshow(img)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-15T04:30:30.421322Z",
     "iopub.execute_input": "2022-03-15T04:30:30.421553Z",
     "iopub.status.idle": "2022-03-15T04:30:34.110725Z",
     "shell.execute_reply.started": "2022-03-15T04:30:30.421519Z",
     "shell.execute_reply": "2022-03-15T04:30:34.109974Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "for i in range(traing_metadata.shape[0]):\n    file_name, label = traing_metadata.iloc[i]\n    \n    if not os.path.isdir('train'):\n        os.mkdir('train')\n        \n    if not os.path.isdir(os.path.join('train',label)):\n        os.mkdir(os.path.join('train', label))\n        \n    src = os.path.join('../input/resizing-high-quality-images/train/', file_name)\n    dst = os.path.join('train',label)\n    img = PIL.Image.open(src)\n    \n    cc_img = cropping(img, central=True, random=False, fraction_low=0.75, fraction_high=0.9, copies=1, save_original=False)\n    cropping(cc_img, file_name, dst=dst, central=False, random=True, random_width=224, random_height=224, copies=5, save_original=False)\n    \n    print(f\"steps: {i + 1}/{traing_metadata.shape[0]} \", end='\\r')",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-15T04:30:34.113528Z",
     "iopub.execute_input": "2022-03-15T04:30:34.113807Z",
     "iopub.status.idle": "2022-03-15T04:44:54.855337Z",
     "shell.execute_reply.started": "2022-03-15T04:30:34.113769Z",
     "shell.execute_reply": "2022-03-15T04:44:54.854602Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "sample = traing_metadata.sample(n=1)\nfigure, axes = plt.subplots(nrows=1, ncols=5, figsize=[16,4], dpi=300)\naxes = axes.ravel()\n\nfor i in range(5):\n    filename, label = sample.iloc[0]\n    src = os.path.join('train', label, f'rc_img_{i}_{filename}')\n    img = PIL.Image.open(src)\n    \n    axes[i].imshow(img)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-15T04:44:54.856669Z",
     "iopub.execute_input": "2022-03-15T04:44:54.856918Z",
     "iopub.status.idle": "2022-03-15T04:44:56.944577Z",
     "shell.execute_reply.started": "2022-03-15T04:44:54.856885Z",
     "shell.execute_reply": "2022-03-15T04:44:56.943826Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "for sub_dir in os.listdir('train'):\n    src = os.path.join('train', sub_dir)\n    dst = os.path.join('train', sub_dir)\n    \n    random_changes_to_color_properties(src, dst)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-15T04:44:56.946014Z",
     "iopub.execute_input": "2022-03-15T04:44:56.946525Z",
     "iopub.status.idle": "2022-03-15T05:11:40.956896Z",
     "shell.execute_reply.started": "2022-03-15T04:44:56.946481Z",
     "shell.execute_reply": "2022-03-15T05:11:40.955727Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "classes = random.choice(os.listdir('train'))\n\nfigure, axes = plt.subplots(nrows=2, ncols=5, figsize=[16,4], dpi=300)\naxes = axes.ravel()\n\nfor i in range(10):\n    file_name = random.choice(os.listdir(os.path.join('train', classes)))\n    src = os.path.join('train',  classes, file_name)\n    img = PIL.Image.open(src)\n    print(file_name)\n    \n    axes[i].imshow(img)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-15T05:11:40.958093Z",
     "iopub.execute_input": "2022-03-15T05:11:40.958347Z",
     "iopub.status.idle": "2022-03-15T05:11:44.103305Z",
     "shell.execute_reply.started": "2022-03-15T05:11:40.958312Z",
     "shell.execute_reply": "2022-03-15T05:11:44.101031Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def inception(x, filters, projection, name=None):\n    f_1x1, f_3x3, f_3x3_reduce, f_5x5, f_5x5_reduce = filters\n    x1 = Conv2D(filters=f_1x1, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n    x3_reducer = Conv2D(filters=f_3x3_reduce, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n    x5_reducer = Conv2D(filters=f_5x5_reduce, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n    pool = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n\n    x3 = Conv2D(filters=f_3x3, kernel_size=(3, 3), strides=(1, 1), activation=relu, padding='same')(x3_reducer)\n    x5 = Conv2D(filters=f_5x5, kernel_size=(5, 5), strides=(1, 1), activation=relu, padding='same')(x5_reducer)\n    proj = Conv2D(filters=projection, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(pool)\n\n    x = concatenate([x1, x3, x5, proj], axis=3, name=name)\n\n    return x\n\n\ndef model_builder(shape, classes):\n    input_layer = Input(shape=shape)\n    x = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), activation=relu, padding='same')(input_layer)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n    x = Conv2D(filters=192, kernel_size=(3, 3), strides=(1, 1), activation=relu, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n    x = inception(x, [64, 128, 96, 32, 16], projection=32, name='inception_3a')\n    x = inception(x, [128, 192, 128, 96, 32], projection=64, name='inception_3b')\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n    x = inception(x, [192, 208, 96, 48, 16], projection=64, name='inception_4a')\n\n    aux_1 = AveragePooling2D(pool_size=(5, 5), strides=(3, 3), padding='valid')(x)\n    aux_1 = Conv2D(filters=128, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='valid')(aux_1)\n    aux_1 = Dense(units=1024, activation=relu)(aux_1)\n    aux_1 = Dropout(rate=0.7)(aux_1)\n    aux_1 = Flatten()(aux_1)\n    aux_out1 = Dense(units=classes, activation=softmax, name='aux_out1')(aux_1)\n\n    x = inception(x, [160, 224, 112, 64, 24], projection=64, name='inception_4b')\n    x = inception(x, [128, 256, 128, 64, 24], projection=64, name='inception_4c')\n    x = inception(x, [112, 288, 144, 64, 32], projection=64, name='inception_4d')\n    x = inception(x, [256, 320, 160, 128, 32], projection=128, name='inception_4e')\n\n    aux_2 = AveragePooling2D(pool_size=(5, 5), strides=(3, 3), padding='valid')(x)\n    aux_2 = Conv2D(filters=128, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='valid')(aux_2)\n    aux_2 = Dense(units=1024, activation=relu)(aux_2)\n    aux_2 = Dropout(rate=0.7)(aux_2)\n    aux_2 = Flatten()(aux_2)\n    aux_out2 = Dense(units=classes, activation=softmax, name='aux_out2')(aux_2)\n\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n    x = inception(x, [256, 320, 160, 128, 32], projection=128, name='inception_5a')\n    x = inception(x, [384, 384, 192, 128, 48], projection=128, name='inception_5b')\n    x = AveragePooling2D(pool_size=(7, 7), strides=(1, 1))(x)\n    x = Dropout(rate=0.4)(x)\n    x = Flatten()(x)\n    output_layer = Dense(units=classes, activation=softmax, name='main_out')(x)\n\n    model = Model(input_layer, [output_layer, aux_out1, aux_out2])\n    model.compile(optimizer=Adam(), loss=categorical_crossentropy,\n                  loss_weights={'main_out': 1, 'aux_out1': 0.3, 'aux_out2': 0.3},\n                  metrics=['accuracy', tfa.metrics.F1Score(num_classes=classes, threshold=0.5)])\n    model.summary()\n\n    return model",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-15T05:11:44.104631Z",
     "iopub.execute_input": "2022-03-15T05:11:44.105065Z",
     "iopub.status.idle": "2022-03-15T05:11:44.140155Z",
     "shell.execute_reply.started": "2022-03-15T05:11:44.105029Z",
     "shell.execute_reply": "2022-03-15T05:11:44.139518Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_generator = ImageDataGenerator(rescale=1 / 255.,\n                                     validation_split=0.3)\n\ntrain_set = train_generator.flow_from_directory('train',\n                                                target_size=(224, 224),\n                                                batch_size=32,\n                                                subset='training')\nval_set = train_generator.flow_from_directory('train',\n                                              target_size=(224, 224),\n                                              batch_size=32,\n                                              subset='validation')",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-15T05:11:44.141506Z",
     "iopub.execute_input": "2022-03-15T05:11:44.141936Z",
     "iopub.status.idle": "2022-03-15T05:12:11.975055Z",
     "shell.execute_reply.started": "2022-03-15T05:11:44.14189Z",
     "shell.execute_reply": "2022-03-15T05:12:11.974341Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model = model_builder((224, 224, 3), 12)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-15T05:12:11.977348Z",
     "iopub.execute_input": "2022-03-15T05:12:11.9776Z",
     "iopub.status.idle": "2022-03-15T05:12:12.788286Z",
     "shell.execute_reply.started": "2022-03-15T05:12:11.977565Z",
     "shell.execute_reply": "2022-03-15T05:12:12.787598Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "early_stop = EarlyStopping(monitor='val_loss',\n                           patience=10,\n                           restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.1,\n                              patience=10)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-15T05:29:51.353526Z",
     "iopub.execute_input": "2022-03-15T05:29:51.353809Z",
     "iopub.status.idle": "2022-03-15T05:29:51.360376Z",
     "shell.execute_reply.started": "2022-03-15T05:29:51.353776Z",
     "shell.execute_reply": "2022-03-15T05:29:51.359423Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "history = model.fit(x=train_set,\n                    validation_data=val_set,\n                    epochs=100,\n                    steps_per_epoch=6114,\n                    validation_steps=2620,\n                    callbacks=[early_stop, reduce_lr])",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-03-15T05:29:58.366359Z",
     "iopub.execute_input": "2022-03-15T05:29:58.366633Z",
     "iopub.status.idle": "2022-03-15T09:48:12.696433Z",
     "shell.execute_reply.started": "2022-03-15T05:29:58.366603Z",
     "shell.execute_reply": "2022-03-15T09:48:12.694543Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "temp = pd.DataFrame(history.history)\ntemp.to_pickle('inception_aux_random_crop_history.pkl')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-15T09:48:12.705653Z",
     "iopub.execute_input": "2022-03-15T09:48:12.706086Z",
     "iopub.status.idle": "2022-03-15T09:48:12.74416Z",
     "shell.execute_reply.started": "2022-03-15T09:48:12.706044Z",
     "shell.execute_reply": "2022-03-15T09:48:12.743249Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "model.save('inception_aux_random_crop.hdf5')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-15T09:48:12.748417Z",
     "iopub.execute_input": "2022-03-15T09:48:12.750466Z",
     "iopub.status.idle": "2022-03-15T09:48:31.76968Z",
     "shell.execute_reply.started": "2022-03-15T09:48:12.75043Z",
     "shell.execute_reply": "2022-03-15T09:48:31.768972Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### VGGNet",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# weight_decay = 5e-4\n\n# def vgg_net16_d(input_shape=(224, 224, 3), classes=None):\n#     # input layer\n#     input_layer = Input(shape=input_shape, name='input_')\n\n#     # first conv block\n#     x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(input_layer)\n#     x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n\n#     # second conv block\n#     x = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n\n#     # third conv block\n#     x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n\n#     # fourth conv block\n#     x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n\n#     # fifth conv block\n#     x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), kernel_regularizer=l2(weight_decay), padding='same',\n#                activation=relu)(x)\n#     x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n\n#     # classifier\n#     x = Flatten()(x)\n#     x = Dense(units=512, activation=relu)(x)\n#     x = Dropout(rate=0.5)(x)\n#     x = Dense(units=512, activation=relu)(x)\n#     x = Dropout(rate=0.5)(x)\n#     x = Dense(units=classes, activation=softmax)(x)\n\n#     model = Model(input_layer, x)\n#     model.compile(optimizer=Adam(), loss=categorical_crossentropy, metrics=['accuracy',tfa.metrics.F1Score(num_classes=classes, threshold=0.5)])\n#     model.summary()\n\n#     return model",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-14T16:36:35.825135Z",
     "iopub.execute_input": "2022-03-14T16:36:35.825569Z",
     "iopub.status.idle": "2022-03-14T16:36:35.853123Z",
     "shell.execute_reply.started": "2022-03-14T16:36:35.825517Z",
     "shell.execute_reply": "2022-03-14T16:36:35.851489Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# vgg_model = vgg_net16_d((224, 224, 3), 12)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-14T16:36:40.432386Z",
     "iopub.execute_input": "2022-03-14T16:36:40.432772Z",
     "iopub.status.idle": "2022-03-14T16:36:40.618245Z",
     "shell.execute_reply.started": "2022-03-14T16:36:40.432739Z",
     "shell.execute_reply": "2022-03-14T16:36:40.617291Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# vgg_history = vgg_model.fit(x=train_set,\n#                     validation_data=val_set,\n#                     epochs=100,\n#                     steps_per_epoch=6114,\n#                     validation_steps=2620,\n#                     callbacks=[early_stop, reduce_lr])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-14T16:36:46.823744Z",
     "iopub.execute_input": "2022-03-14T16:36:46.824207Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# temp = pd.DataFrame(vgg_history.history)\n# temp.to_pickle('vgg_random_crop_history.pkl')",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# model.save('vgg_random_crop.hdf5')",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# model.save('vgg_random_crop.hdf5')",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}