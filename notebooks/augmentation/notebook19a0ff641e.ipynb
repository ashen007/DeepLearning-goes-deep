{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-03-25T12:56:51.042467Z",
     "iopub.execute_input": "2022-03-25T12:56:51.043024Z",
     "iopub.status.idle": "2022-03-25T12:56:56.478128Z",
     "shell.execute_reply.started": "2022-03-25T12:56:51.042931Z",
     "shell.execute_reply": "2022-03-25T12:56:56.477356Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T12:56:56.479796Z",
     "iopub.execute_input": "2022-03-25T12:56:56.480032Z",
     "iopub.status.idle": "2022-03-25T12:56:56.597937Z",
     "shell.execute_reply.started": "2022-03-25T12:56:56.480002Z",
     "shell.execute_reply": "2022-03-25T12:56:56.597269Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_dir = '../input/leaf-disease-dataset-combination/image data/'\n",
    "reg_dir = os.path.join(data_dir, 'validation')\n",
    "train_dir = os.path.join(data_dir, 'train')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T12:56:56.599525Z",
     "iopub.execute_input": "2022-03-25T12:56:56.599923Z",
     "iopub.status.idle": "2022-03-25T12:56:56.604402Z",
     "shell.execute_reply.started": "2022-03-25T12:56:56.599888Z",
     "shell.execute_reply": "2022-03-25T12:56:56.603425Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.isdir('train'):\n",
    "    os.mkdir('train')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T12:56:56.606958Z",
     "iopub.execute_input": "2022-03-25T12:56:56.607203Z",
     "iopub.status.idle": "2022-03-25T12:56:56.613350Z",
     "shell.execute_reply.started": "2022-03-25T12:56:56.607171Z",
     "shell.execute_reply": "2022-03-25T12:56:56.612631Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for dir in os.listdir(reg_dir):\n",
    "    if dir != 'Cassava':\n",
    "        sub_dir_path = os.path.join(reg_dir, dir)\n",
    "\n",
    "        for subclass in os.listdir(sub_dir_path):\n",
    "            dst_dir = os.path.join('train',f\"{dir}-{subclass}\")\n",
    "\n",
    "            if not os.path.isdir(dst_dir):\n",
    "                os.mkdir(dst_dir)\n",
    "\n",
    "            for key, file in enumerate(os.listdir(os.path.join(sub_dir_path, subclass))):\n",
    "                src = os.path.join(sub_dir_path, subclass, file)\n",
    "                dst = os.path.join(dst_dir, file)\n",
    "                shutil.copyfile(src, dst)\n",
    "\n",
    "                print(f'{key + 1}/{len(os.listdir(os.path.join(sub_dir_path, subclass)))}', end='\\r')\n",
    "\n",
    "            print(f'{os.path.join(reg_dir,dir, subclass)}-->{dst_dir}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T12:56:56.614628Z",
     "iopub.execute_input": "2022-03-25T12:56:56.614879Z",
     "iopub.status.idle": "2022-03-25T12:57:51.206965Z",
     "shell.execute_reply.started": "2022-03-25T12:56:56.614836Z",
     "shell.execute_reply": "2022-03-25T12:57:51.206252Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for dir in os.listdir(train_dir):\n",
    "    if dir != 'Cassava':\n",
    "        sub_dir_path = os.path.join(train_dir, dir)\n",
    "\n",
    "        for subclass in os.listdir(sub_dir_path):\n",
    "            dst_dir = os.path.join('train',f\"{dir}-{subclass}\")\n",
    "\n",
    "            if not os.path.isdir(dst_dir):\n",
    "                os.mkdir(dst_dir)\n",
    "\n",
    "            for key, file in enumerate(os.listdir(os.path.join(sub_dir_path, subclass))):\n",
    "                src = os.path.join(sub_dir_path, subclass, file)\n",
    "                dst = os.path.join(dst_dir, file)\n",
    "                shutil.copyfile(src, dst)\n",
    "\n",
    "                print(f'{key + 1}/{len(os.listdir(os.path.join(sub_dir_path, subclass)))}', end='\\r')\n",
    "\n",
    "            print(f'{os.path.join(train_dir,dir, subclass)}-->{dst_dir}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T12:57:51.208076Z",
     "iopub.execute_input": "2022-03-25T12:57:51.208319Z",
     "iopub.status.idle": "2022-03-25T13:02:15.566896Z",
     "shell.execute_reply.started": "2022-03-25T12:57:51.208284Z",
     "shell.execute_reply": "2022-03-25T13:02:15.566200Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loacl_train_dir = 'train'"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:02:15.568313Z",
     "iopub.execute_input": "2022-03-25T13:02:15.568566Z",
     "iopub.status.idle": "2022-03-25T13:02:15.572293Z",
     "shell.execute_reply.started": "2022-03-25T13:02:15.568531Z",
     "shell.execute_reply": "2022-03-25T13:02:15.571481Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dp_ = {}\n",
    "sizes = []\n",
    "\n",
    "for top in os.listdir(loacl_train_dir):\n",
    "    path = os.path.join(loacl_train_dir, top)\n",
    "    dp_[top] = len(os.listdir(path))\n",
    "    sizes.append(len(os.listdir(path)))\n",
    "\n",
    "pprint.pprint(dp_)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:02:15.573257Z",
     "iopub.execute_input": "2022-03-25T13:02:15.573656Z",
     "iopub.status.idle": "2022-03-25T13:02:15.640163Z",
     "shell.execute_reply.started": "2022-03-25T13:02:15.573621Z",
     "shell.execute_reply": "2022-03-25T13:02:15.639545Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for top in os.listdir(loacl_train_dir):\n",
    "    path = os.path.join(loacl_train_dir, top)\n",
    "\n",
    "    if len(os.listdir(path)) == 0:\n",
    "        print(f'{path} -- removed')\n",
    "        os.rmdir(path)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:02:15.641212Z",
     "iopub.execute_input": "2022-03-25T13:02:15.642155Z",
     "iopub.status.idle": "2022-03-25T13:02:15.669945Z",
     "shell.execute_reply.started": "2022-03-25T13:02:15.642119Z",
     "shell.execute_reply": "2022-03-25T13:02:15.669311Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def change_contrast(image, lower, upper, copies=1):\n",
    "    copies = [tf.image.random_contrast(image, lower=lower, upper=upper) for _ in range(copies)]\n",
    "    return copies\n",
    "\n",
    "\n",
    "def change_brightness(image, delta, copies=1):\n",
    "    copies = [tf.image.random_brightness(image, max_delta=delta) for _ in range(copies)]\n",
    "    return copies\n",
    "\n",
    "\n",
    "def change_hue(image, delta, copies=1):\n",
    "    copies = [tf.image.random_hue(image, max_delta=delta) for _ in range(copies)]\n",
    "    return copies\n",
    "\n",
    "\n",
    "def gamma_transformation(image, gamma=0.3, copies=1):\n",
    "    low = 1 - gamma\n",
    "    up = 1 + gamma\n",
    "    copies = [tf.image.adjust_gamma(image, gamma=np.random.uniform(low, up, 1)) for _ in range(copies)]\n",
    "    return copies\n",
    "\n",
    "def load_img_to_array(path):\n",
    "    return img_to_array(load_img(path))\n",
    "\n",
    "\n",
    "def resize(image, size):\n",
    "    return tf.image.resize(image, size)\n",
    "\n",
    "\n",
    "def bounding_boxes(offsets, dim):\n",
    "    boxes = []\n",
    "\n",
    "    for i in offsets:\n",
    "        offset_height, offset_width = i\n",
    "        target_height, target_width = dim\n",
    "        boxes.append([offset_height, offset_width, target_height, target_width])\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def random_sectioning(image, offsets, dims):\n",
    "    boxes = bounding_boxes(offsets, dims)\n",
    "    image_sections = []\n",
    "\n",
    "    for box in boxes:\n",
    "        if random.choice([True, False]):\n",
    "            section = tf.image.crop_to_bounding_box(image, box[0], box[1], box[2], box[3])\n",
    "            image_sections.append(section)\n",
    "\n",
    "    return image_sections\n",
    "\n",
    "\n",
    "def aggressive_cropping(image, copies, crop_window, resize_smallest_side, output_shape):\n",
    "    global img, resized_copies, crops\n",
    "\n",
    "    if isinstance(resize_smallest_side, int):\n",
    "        img = resize(image, (resize_smallest_side, resize_smallest_side))\n",
    "\n",
    "    if isinstance(resize_smallest_side, (list, tuple)):\n",
    "        resized_copies = [tf.image.resize(image, (size, size)) for size in resize_smallest_side]\n",
    "\n",
    "    if isinstance(crop_window, int):\n",
    "        if isinstance(resize_smallest_side, int):\n",
    "            crops = [tf.image.random_crop(img, crop_window) for _ in range(copies)]\n",
    "        elif isinstance(resize_smallest_side, (list, tuple)):\n",
    "            crops = [tf.image.random_crop(img_, crop_window) for _ in range(copies) for img_ in\n",
    "                     resized_copies]\n",
    "\n",
    "    elif isinstance(crop_window, (list, tuple)):\n",
    "        if isinstance(resize_smallest_side, int):\n",
    "            crops = [tf.image.random_crop(img, crop_window) for _ in range(copies)]\n",
    "        elif isinstance(resize_smallest_side, (list, tuple)):\n",
    "            crops = [tf.image.random_crop(img_, crop_window) for _ in range(copies) for img_ in resized_copies]\n",
    "\n",
    "    return [resize(crop_img, output_shape) for crop_img in crops]\n",
    "\n",
    "\n",
    "def change_contrast(image, lower, upper, copies=1):\n",
    "    copies = [tf.image.random_contrast(image, lower=lower, upper=upper) for _ in range(copies)]\n",
    "    return copies\n",
    "\n",
    "\n",
    "def change_brightness(image, delta, copies=1):\n",
    "    copies = [tf.image.random_brightness(image, max_delta=delta) for _ in range(copies)]\n",
    "    return copies\n",
    "\n",
    "\n",
    "def change_hue(image, delta, copies=1):\n",
    "    copies = [tf.image.random_hue(image, max_delta=delta) for _ in range(copies)]\n",
    "    return copies\n",
    "\n",
    "\n",
    "def gamma_transformation(image, gamma=0.3, copies=1):\n",
    "    low = 1 - gamma\n",
    "    up = 1 + gamma\n",
    "    copies = [tf.image.adjust_gamma(image, gamma=np.random.uniform(low, up, 1)) for _ in range(copies)]\n",
    "    return copies"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:02:15.672705Z",
     "iopub.execute_input": "2022-03-25T13:02:15.673015Z",
     "iopub.status.idle": "2022-03-25T13:02:15.695567Z",
     "shell.execute_reply.started": "2022-03-25T13:02:15.672983Z",
     "shell.execute_reply": "2022-03-25T13:02:15.694509Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dir_path = []\n",
    "\n",
    "for top in os.listdir(loacl_train_dir):\n",
    "    path = os.path.join(loacl_train_dir, top)\n",
    "\n",
    "    if 1000 < len(os.listdir(path)) < 3000:\n",
    "        dir_path.append(path)\n",
    "\n",
    "dir_path"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:02:15.698175Z",
     "iopub.execute_input": "2022-03-25T13:02:15.698364Z",
     "iopub.status.idle": "2022-03-25T13:02:15.734710Z",
     "shell.execute_reply.started": "2022-03-25T13:02:15.698335Z",
     "shell.execute_reply": "2022-03-25T13:02:15.733750Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for file_dir in dir_path:\n",
    "    before = len(os.listdir(file_dir))\n",
    "    size_before = len(os.listdir(file_dir))\n",
    "    original_files = enumerate(os.listdir(file_dir))\n",
    "\n",
    "    for key_, file in original_files:\n",
    "        img_path = os.path.join(file_dir, file)\n",
    "        img = load_img(img_path)\n",
    "        height, width = img_to_array(img).shape[:2]\n",
    "        cropped = random_sectioning(img_to_array(img),\n",
    "                                    [[0, 0], [height // 2, 0], [0, width // 2], [height // 2, width // 2],\n",
    "                                     [height // 4, width // 4]],\n",
    "                                    [height // 2, width // 2])\n",
    "\n",
    "        for key, section in enumerate(cropped):\n",
    "            if len(os.listdir(file_dir)) > 5555:\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                section_file_name = f\"sec-crop-{key}-{file}\"\n",
    "                dst_path = os.path.join(file_dir, section_file_name)\n",
    "                array_to_img(section).save(dst_path)\n",
    "\n",
    "        print(f'{key_ + 1}/{size_before}', end='\\r')\n",
    "\n",
    "    print(f'{file_dir} -- Done -- {before}-->{len(os.listdir(file_dir))}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:02:15.735900Z",
     "iopub.execute_input": "2022-03-25T13:02:15.736191Z",
     "iopub.status.idle": "2022-03-25T13:05:16.474016Z",
     "shell.execute_reply.started": "2022-03-25T13:02:15.736157Z",
     "shell.execute_reply": "2022-03-25T13:05:16.473264Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dir_path_small = []\n",
    "\n",
    "for top in os.listdir(loacl_train_dir):\n",
    "    path = os.path.join(loacl_train_dir, top)\n",
    "\n",
    "    if len(os.listdir(path)) < 1000:\n",
    "        dir_path_small.append(path)\n",
    "\n",
    "dir_path_small"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:05:16.475412Z",
     "iopub.execute_input": "2022-03-25T13:05:16.475818Z",
     "iopub.status.idle": "2022-03-25T13:05:16.552360Z",
     "shell.execute_reply.started": "2022-03-25T13:05:16.475781Z",
     "shell.execute_reply": "2022-03-25T13:05:16.551288Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for file_dir in dir_path_small:\n",
    "    before = len(os.listdir(file_dir))\n",
    "    size_before = len(os.listdir(file_dir))\n",
    "    original_files = enumerate(os.listdir(file_dir))\n",
    "\n",
    "    for key_, file in original_files:\n",
    "        img_path = os.path.join(file_dir, file)\n",
    "        img = load_img(img_path)\n",
    "        cropped = aggressive_cropping(img_to_array(img), 2, (128, 128, 3), [256, 288, 320, 352], (128, 128))\n",
    "\n",
    "        for key, section in enumerate(cropped):\n",
    "            if len(os.listdir(file_dir)) > 5555:\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                section_file_name = f\"agr-crop-{key}-{file}\"\n",
    "                dst_path = os.path.join(file_dir, section_file_name)\n",
    "                array_to_img(section).save(dst_path)\n",
    "\n",
    "        print(f'{key_ + 1}/{size_before}', end='\\r')\n",
    "\n",
    "    print(f'{file_dir} -- Done -- {before}-->{len(os.listdir(file_dir))}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:05:16.554037Z",
     "iopub.execute_input": "2022-03-25T13:05:16.554395Z",
     "iopub.status.idle": "2022-03-25T13:14:01.509020Z",
     "shell.execute_reply.started": "2022-03-25T13:05:16.554349Z",
     "shell.execute_reply": "2022-03-25T13:14:01.508262Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for tree in os.listdir(loacl_train_dir):\n",
    "    tree_path = os.path.join(loacl_train_dir, tree)\n",
    "    original_files = os.listdir(tree_path)\n",
    "\n",
    "    for key_, file in enumerate(original_files):\n",
    "        img = img_to_array(load_img(os.path.join(tree_path, file)))\n",
    "\n",
    "        array_to_img(change_contrast(img, 0.5, 1.5)[0]).save(os.path.join(tree_path, f'con-man-{key_}-{file}'))\n",
    "        array_to_img(change_brightness(img, 0.3)[0]).save(os.path.join(tree_path, f'b-man-{key_}-{file}'))\n",
    "        array_to_img(change_hue(img, 0.5)[0]).save(os.path.join(tree_path, f'hue-man-{key_}-{file}'))\n",
    "        array_to_img(gamma_transformation(img, 0.6)[0]).save(os.path.join(tree_path, f'gamma-man-{key_}-{file}'))\n",
    "\n",
    "        print(f'{key_ + 1}/{len(original_files)}', end='\\r')\n",
    "\n",
    "    print(f'{tree_path} -- Done -- {len(original_files)}-->{len(os.listdir(tree_path))}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:14:01.510150Z",
     "iopub.execute_input": "2022-03-25T13:14:01.510398Z",
     "iopub.status.idle": "2022-03-25T13:44:40.454218Z",
     "shell.execute_reply.started": "2022-03-25T13:14:01.510349Z",
     "shell.execute_reply": "2022-03-25T13:44:40.453497Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generator = ImageDataGenerator(rescale=1/255.,\n",
    "                              validation_split=0.3)\n",
    "\n",
    "train_batch = generator.flow_from_directory(directory='train',\n",
    "                                           target_size=(224,224),\n",
    "                                           subset='training')\n",
    "\n",
    "validation_batch = generator.flow_from_directory(directory='train',\n",
    "                                           target_size=(224,224),\n",
    "                                           subset='validation')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:44:40.455350Z",
     "iopub.execute_input": "2022-03-25T13:44:40.455766Z",
     "iopub.status.idle": "2022-03-25T13:45:29.243000Z",
     "shell.execute_reply.started": "2022-03-25T13:44:40.455729Z",
     "shell.execute_reply": "2022-03-25T13:45:29.242260Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def inception(x, filters, projection, classes=None, aux=False, name=None, aux_name=None):\n",
    "    f_1x1, f_3x3, f_3x3_reduce, f_5x5, f_5x5_reduce = filters\n",
    "    x1 = Conv2D(filters=f_1x1, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n",
    "    x3_reducer = Conv2D(filters=f_3x3_reduce, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n",
    "    x5_reducer = Conv2D(filters=f_5x5_reduce, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n",
    "    pool = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "\n",
    "    x3 = Conv2D(filters=f_3x3, kernel_size=(3, 3), strides=(1, 1), activation=relu, padding='same')(x3_reducer)\n",
    "    x5 = Conv2D(filters=f_5x5, kernel_size=(5, 5), strides=(1, 1), activation=relu, padding='same')(x5_reducer)\n",
    "    proj = Conv2D(filters=projection, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(pool)\n",
    "\n",
    "    x = concatenate([x1, x3, x5, proj], axis=3, name=name)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def model_builder(shape, classes):\n",
    "    input_layer = Input(shape=shape)\n",
    "    x = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), activation=relu, padding='same')(input_layer)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='same')(x)\n",
    "    x = Conv2D(filters=192, kernel_size=(3, 3), strides=(1, 1), activation=relu, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception(x, [64, 128, 96, 32, 16], projection=32, name='inception_3a')\n",
    "    x = inception(x, [128, 192, 128, 96, 32], projection=64, name='inception_3b')\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception(x, [192, 208, 96, 48, 16], projection=64, name='inception_4a')\n",
    "\n",
    "    aux_1 = AveragePooling2D(pool_size=(5, 5), strides=(3, 3), padding='valid')(x)\n",
    "    aux_1 = Conv2D(filters=128, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='valid')(aux_1)\n",
    "    aux_1 = Dense(units=1024, activation=relu)(aux_1)\n",
    "    aux_1 = Dropout(rate=0.7)(aux_1)\n",
    "    aux_1 = Flatten()(aux_1)\n",
    "    aux_out1 = Dense(units=classes, activation=softmax, name='aux_out1')(aux_1)\n",
    "\n",
    "    x = inception(x, [160, 224, 112, 64, 24], projection=64, name='inception_4b')\n",
    "    x = inception(x, [128, 256, 128, 64, 24], projection=64, name='inception_4c')\n",
    "    x = inception(x, [112, 288, 144, 64, 32], projection=64, name='inception_4d')\n",
    "    x = inception(x, [256, 320, 160, 128, 32], projection=128, name='inception_4e')\n",
    "\n",
    "    aux_2 = AveragePooling2D(pool_size=(5, 5), strides=(3, 3), padding='valid')(x)\n",
    "    aux_2 = Conv2D(filters=128, kernel_size=(1, 1), strides=(1, 1), activation=relu, padding='valid')(aux_2)\n",
    "    aux_2 = Dense(units=1024, activation=relu)(aux_2)\n",
    "    aux_2 = Dropout(rate=0.7)(aux_2)\n",
    "    aux_2 = Flatten()(aux_2)\n",
    "    aux_out2 = Dense(units=classes, activation=softmax, name='aux_out2')(aux_2)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception(x, [256, 320, 160, 128, 32], projection=128, name='inception_5a')\n",
    "    x = inception(x, [384, 384, 192, 128, 48], projection=128, name='inception_5b')\n",
    "    x = AveragePooling2D(pool_size=(7, 7), strides=(1, 1))(x)\n",
    "    x = Dropout(rate=0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    output_layer = Dense(units=classes, activation=softmax, name='main_out')(x)\n",
    "\n",
    "    model = Model(input_layer, [output_layer, aux_out1, aux_out2])\n",
    "    model.compile(optimizer=Adam(), loss=categorical_crossentropy,\n",
    "                  loss_weights={'main_out': 1, 'aux_out1': 0.3, 'aux_out2': 0.3},\n",
    "                  metrics=['accuracy', tfa.metrics.F1Score(num_classes=classes, threshold=0.5)])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:45:29.247335Z",
     "iopub.execute_input": "2022-03-25T13:45:29.249264Z",
     "iopub.status.idle": "2022-03-25T13:45:29.306534Z",
     "shell.execute_reply.started": "2022-03-25T13:45:29.249225Z",
     "shell.execute_reply": "2022-03-25T13:45:29.305643Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inception = model_builder(shape=(224, 224, 3), classes=39)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=1e-1, patience=15)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "inception_history = inception.fit(x=train_batch,\n",
    "                              epochs=100,\n",
    "                              steps_per_epoch=6000,\n",
    "                              validation_steps=2000,\n",
    "                              validation_data=validation_batch,\n",
    "                              callbacks=[reduce_lr, early_stop])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-25T13:45:30.046830Z",
     "iopub.execute_input": "2022-03-25T13:45:30.047089Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "temp = pd.DataFrame(inception_history.history)\n",
    "temp.to_pikkel('inception_history.pkl')"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inception.save('inception.hdf5')"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}